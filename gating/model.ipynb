{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-13T02:00:54.588304Z",
     "start_time": "2025-12-13T02:00:51.039011Z"
    }
   },
   "source": [
    "import sys\n",
    "sys.path.insert(0, r\"C:\\Users\\michellexu\\Pulse\\engine\\src\\python\\pulse\\rl-hemorrhage-resuscitation\\gating\")\n",
    "\n",
    "from torch import nn\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import joblib"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T02:01:16.302997Z",
     "start_time": "2025-12-13T02:01:16.262481Z"
    }
   },
   "cell_type": "code",
   "source": [
    "script_dir = script_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(script_dir)\n",
    "\n",
    "data = pd.read_csv(os.path.join(script_dir, \"train_data_bv.csv\"))\n",
    "data[\"dbv1\"] = data[\"bv1\"] - data[\"bv2\"]\n",
    "data[\"dbv2\"] = data[\"bv2\"] - data[\"bv3\"]\n",
    "filtered = data[(data[\"severity\"] != 0.35) & (data[\"severity\"] != 0.15)]\n",
    "data = filtered\n",
    "data"
   ],
   "id": "c0e29b3b6d3fd54f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              bv1          bv2          bv3  severity  label        dbv1  \\\n",
       "0     4672.020119  4661.731009  4651.516970      0.05      0   10.289111   \n",
       "1     4672.020119  4649.813507  4627.959100      0.10      0   22.206613   \n",
       "3     4672.020119  4652.312035  4633.303977      0.50      0   19.708085   \n",
       "4     4672.020119  4646.909993  4622.921291      0.60      0   25.110126   \n",
       "5     4672.020119  4641.411392  4612.436327      0.70      0   30.608727   \n",
       "...           ...          ...          ...       ...    ...         ...   \n",
       "2094  3755.683265  3694.985034  3637.396574      0.25      1   60.698232   \n",
       "2095  3755.683265  3680.153955  3609.281895      0.30      1   75.529310   \n",
       "2097  3755.683265  3648.306231  3550.103007      0.40      1  107.377035   \n",
       "2098  3755.683265  3718.991026  3684.734201      0.90      1   36.692239   \n",
       "2099  3755.683265  3715.240089  3677.723948      1.00      1   40.443176   \n",
       "\n",
       "           dbv2  \n",
       "0     10.214038  \n",
       "1     21.854407  \n",
       "3     19.008058  \n",
       "4     23.988702  \n",
       "5     28.975065  \n",
       "...         ...  \n",
       "2094  57.588460  \n",
       "2095  70.872060  \n",
       "2097  98.203224  \n",
       "2098  34.256825  \n",
       "2099  37.516141  \n",
       "\n",
       "[1800 rows x 7 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bv1</th>\n",
       "      <th>bv2</th>\n",
       "      <th>bv3</th>\n",
       "      <th>severity</th>\n",
       "      <th>label</th>\n",
       "      <th>dbv1</th>\n",
       "      <th>dbv2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4672.020119</td>\n",
       "      <td>4661.731009</td>\n",
       "      <td>4651.516970</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>10.289111</td>\n",
       "      <td>10.214038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4672.020119</td>\n",
       "      <td>4649.813507</td>\n",
       "      <td>4627.959100</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "      <td>22.206613</td>\n",
       "      <td>21.854407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4672.020119</td>\n",
       "      <td>4652.312035</td>\n",
       "      <td>4633.303977</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>19.708085</td>\n",
       "      <td>19.008058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4672.020119</td>\n",
       "      <td>4646.909993</td>\n",
       "      <td>4622.921291</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0</td>\n",
       "      <td>25.110126</td>\n",
       "      <td>23.988702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4672.020119</td>\n",
       "      <td>4641.411392</td>\n",
       "      <td>4612.436327</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0</td>\n",
       "      <td>30.608727</td>\n",
       "      <td>28.975065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2094</th>\n",
       "      <td>3755.683265</td>\n",
       "      <td>3694.985034</td>\n",
       "      <td>3637.396574</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>60.698232</td>\n",
       "      <td>57.588460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>3755.683265</td>\n",
       "      <td>3680.153955</td>\n",
       "      <td>3609.281895</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1</td>\n",
       "      <td>75.529310</td>\n",
       "      <td>70.872060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>3755.683265</td>\n",
       "      <td>3648.306231</td>\n",
       "      <td>3550.103007</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1</td>\n",
       "      <td>107.377035</td>\n",
       "      <td>98.203224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>3755.683265</td>\n",
       "      <td>3718.991026</td>\n",
       "      <td>3684.734201</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>36.692239</td>\n",
       "      <td>34.256825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>3755.683265</td>\n",
       "      <td>3715.240089</td>\n",
       "      <td>3677.723948</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>40.443176</td>\n",
       "      <td>37.516141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1800 rows Ã— 7 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T02:01:17.333699Z",
     "start_time": "2025-12-13T02:01:17.325604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_np = data.iloc[:, 5:].to_numpy()\n",
    "y_np = data.iloc[:, 4].to_numpy()\n",
    "X_np[0]"
   ],
   "id": "a3fca80534451e17",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.2891108 , 10.21403818])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T02:01:18.060539Z",
     "start_time": "2025-12-13T02:01:18.050273Z"
    }
   },
   "cell_type": "code",
   "source": "X_np",
   "id": "f65afab0a88ac8e4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10.2891108 ,  10.21403818],\n",
       "       [ 22.20661258,  21.85440654],\n",
       "       [ 19.70808453,  19.00805761],\n",
       "       ...,\n",
       "       [107.37703453,  98.20322359],\n",
       "       [ 36.69223895,  34.25682481],\n",
       "       [ 40.44317647,  37.5161412 ]], shape=(1800, 2))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T02:01:19.436733Z",
     "start_time": "2025-12-13T02:01:19.424347Z"
    }
   },
   "cell_type": "code",
   "source": "y_np",
   "id": "35dd94e05f5d1e51",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1], shape=(1800,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T02:01:32.185422Z",
     "start_time": "2025-12-13T02:01:30.821735Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X_np, y_np, test_size=0.3, random_state=42, shuffle=True, stratify=y_np)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, shuffle=True, stratify=y_temp)\n",
    "\n",
    "X_train_np = X_train\n",
    "X_val_np = X_val\n",
    "X_test_np = X_test\n",
    "\n",
    "# fit scaler on training data only\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_np)\n",
    "\n",
    "# apply same transformation to val/test\n",
    "X_val_scaled = scaler.transform(X_val_np)\n",
    "X_test_scaled = scaler.transform(X_test_np)\n",
    "\n",
    "# optionally save scaler for later use (inverse transform / inference)\n",
    "joblib.dump(scaler, os.path.join(script_dir, \"gating_scaler.pkl\"))\n",
    "\n",
    "# convert to torch tensors\n",
    "X_train = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "X_val = torch.tensor(X_val_scaled, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val, dtype=torch.long)\n",
    "X_test = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "class GatingNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features=2, out_features=32)\n",
    "        self.fc2 = nn.Linear(in_features=32, out_features=32)\n",
    "        self.fc3 = nn.Linear(in_features=32, out_features=16)\n",
    "        self.fc4 = nn.Linear(in_features=16, out_features=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return self.fc4(x)\n",
    "\n",
    "model = GatingNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "n_epochs = 50\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        total += 1\n",
    "        # if i % 5 == 1:    # print every 2 mini-batches\n",
    "        #     print(f\"[{epoch + 1}, {i + 1}] loss: {running_loss / 5:.3f}\")\n",
    "        #     running_loss = 0.0\n",
    "    avg_train_loss = running_loss / total\n",
    "    #train_acc = correct / total\n",
    "\n",
    "    # validation pass\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            #inputs = inputs.to(device)\n",
    "            #labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_acc = correct / total if total > 0 else 0.0\n",
    "    print(f\"Finished epoch #{epoch + 1} train_loss: {avg_train_loss:.4f} val_loss: {avg_val_loss:.4f} val_acc: {val_acc:.4f}\")\n",
    "\n",
    "\n",
    "save_path = os.path.join(script_dir, \"gating_model.pth\")\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(\"Finished Training and saved model at\", save_path)"
   ],
   "id": "49a8bd9efae405d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch #1 train_loss: 0.6858 val_loss: 0.6497 val_acc: 0.5000\n",
      "Finished epoch #2 train_loss: 0.6434 val_loss: 0.6035 val_acc: 0.5741\n",
      "Finished epoch #3 train_loss: 0.5992 val_loss: 0.5491 val_acc: 0.9222\n",
      "Finished epoch #4 train_loss: 0.5455 val_loss: 0.4801 val_acc: 0.9593\n",
      "Finished epoch #5 train_loss: 0.4791 val_loss: 0.4011 val_acc: 0.9704\n",
      "Finished epoch #6 train_loss: 0.4043 val_loss: 0.3193 val_acc: 0.9741\n",
      "Finished epoch #7 train_loss: 0.3276 val_loss: 0.2447 val_acc: 0.9741\n",
      "Finished epoch #8 train_loss: 0.2584 val_loss: 0.1836 val_acc: 0.9704\n",
      "Finished epoch #9 train_loss: 0.2022 val_loss: 0.1406 val_acc: 0.9741\n",
      "Finished epoch #10 train_loss: 0.1635 val_loss: 0.1109 val_acc: 0.9741\n",
      "Finished epoch #11 train_loss: 0.1360 val_loss: 0.0909 val_acc: 0.9741\n",
      "Finished epoch #12 train_loss: 0.1179 val_loss: 0.0790 val_acc: 0.9741\n",
      "Finished epoch #13 train_loss: 0.1082 val_loss: 0.0722 val_acc: 0.9741\n",
      "Finished epoch #14 train_loss: 0.1006 val_loss: 0.0675 val_acc: 0.9667\n",
      "Finished epoch #15 train_loss: 0.0974 val_loss: 0.0655 val_acc: 0.9741\n",
      "Finished epoch #16 train_loss: 0.0945 val_loss: 0.0628 val_acc: 0.9667\n",
      "Finished epoch #17 train_loss: 0.0926 val_loss: 0.0640 val_acc: 0.9741\n",
      "Finished epoch #18 train_loss: 0.0905 val_loss: 0.0611 val_acc: 0.9667\n",
      "Finished epoch #19 train_loss: 0.0899 val_loss: 0.0606 val_acc: 0.9667\n",
      "Finished epoch #20 train_loss: 0.0895 val_loss: 0.0612 val_acc: 0.9741\n",
      "Finished epoch #21 train_loss: 0.0888 val_loss: 0.0612 val_acc: 0.9741\n",
      "Finished epoch #22 train_loss: 0.0886 val_loss: 0.0602 val_acc: 0.9667\n",
      "Finished epoch #23 train_loss: 0.0918 val_loss: 0.0596 val_acc: 0.9667\n",
      "Finished epoch #24 train_loss: 0.0893 val_loss: 0.0623 val_acc: 0.9741\n",
      "Finished epoch #25 train_loss: 0.0895 val_loss: 0.0601 val_acc: 0.9667\n",
      "Finished epoch #26 train_loss: 0.0894 val_loss: 0.0598 val_acc: 0.9667\n",
      "Finished epoch #27 train_loss: 0.0878 val_loss: 0.0611 val_acc: 0.9741\n",
      "Finished epoch #28 train_loss: 0.0891 val_loss: 0.0599 val_acc: 0.9667\n",
      "Finished epoch #29 train_loss: 0.0887 val_loss: 0.0599 val_acc: 0.9667\n",
      "Finished epoch #30 train_loss: 0.0890 val_loss: 0.0612 val_acc: 0.9741\n",
      "Finished epoch #31 train_loss: 0.0888 val_loss: 0.0594 val_acc: 0.9667\n",
      "Finished epoch #32 train_loss: 0.0892 val_loss: 0.0596 val_acc: 0.9667\n",
      "Finished epoch #33 train_loss: 0.0888 val_loss: 0.0599 val_acc: 0.9667\n",
      "Finished epoch #34 train_loss: 0.0892 val_loss: 0.0597 val_acc: 0.9667\n",
      "Finished epoch #35 train_loss: 0.0885 val_loss: 0.0600 val_acc: 0.9667\n",
      "Finished epoch #36 train_loss: 0.0885 val_loss: 0.0607 val_acc: 0.9741\n",
      "Finished epoch #37 train_loss: 0.0869 val_loss: 0.0590 val_acc: 0.9667\n",
      "Finished epoch #38 train_loss: 0.0870 val_loss: 0.0596 val_acc: 0.9667\n",
      "Finished epoch #39 train_loss: 0.0890 val_loss: 0.0593 val_acc: 0.9667\n",
      "Finished epoch #40 train_loss: 0.0882 val_loss: 0.0598 val_acc: 0.9667\n",
      "Finished epoch #41 train_loss: 0.0883 val_loss: 0.0603 val_acc: 0.9704\n",
      "Finished epoch #42 train_loss: 0.0882 val_loss: 0.0592 val_acc: 0.9667\n",
      "Finished epoch #43 train_loss: 0.0880 val_loss: 0.0598 val_acc: 0.9667\n",
      "Finished epoch #44 train_loss: 0.0879 val_loss: 0.0592 val_acc: 0.9667\n",
      "Finished epoch #45 train_loss: 0.0873 val_loss: 0.0597 val_acc: 0.9667\n",
      "Finished epoch #46 train_loss: 0.0872 val_loss: 0.0591 val_acc: 0.9667\n",
      "Finished epoch #47 train_loss: 0.0882 val_loss: 0.0602 val_acc: 0.9704\n",
      "Finished epoch #48 train_loss: 0.0892 val_loss: 0.0588 val_acc: 0.9667\n",
      "Finished epoch #49 train_loss: 0.0896 val_loss: 0.0609 val_acc: 0.9741\n",
      "Finished epoch #50 train_loss: 0.0892 val_loss: 0.0585 val_acc: 0.9667\n",
      "Finished Training and saved model at C:\\Users\\michellexu\\Pulse\\engine\\src\\python\\pulse\\rl-hemorrhage-resuscitation\\gating\\gating_model.pth\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T02:01:27.151435Z",
     "start_time": "2025-12-13T02:01:23.691792Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# python\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# load data (adjust path as needed)\n",
    "script_dir = os.getcwd()\n",
    "data = pd.read_csv(os.path.join(script_dir, \"train_data_bv.csv\"))\n",
    "data[\"dbv1\"] = data[\"bv1\"] - data[\"bv2\"]\n",
    "data[\"dbv2\"] = data[\"bv2\"] - data[\"bv3\"]\n",
    "data = data[data[\"severity\"] != 0.35]\n",
    "\n",
    "# features / labels: adjust column indices/names to your dataset\n",
    "X = data.iloc[:, 5:].to_numpy()        # all feature columns from col index 5\n",
    "y = data.iloc[:, 4].to_numpy().astype(int)  # label column at index 4\n",
    "\n",
    "# Make sure you actually have the rows you expect\n",
    "assert X.shape[0] == y.shape[0], \"Feature / label row mismatch\"\n",
    "\n",
    "# split\n",
    "X_train_np, X_temp, y_train_np, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, shuffle=True, stratify=y\n",
    ")\n",
    "X_val_np, X_test_np, y_val_np, y_test_np = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, shuffle=True, stratify=y_temp\n",
    ")\n",
    "\n",
    "# scale: fit only on train\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_np)\n",
    "X_val_scaled = scaler.transform(X_val_np)\n",
    "X_test_scaled = scaler.transform(X_test_np)\n",
    "\n",
    "# to tensors\n",
    "X_train = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train_np, dtype=torch.long)\n",
    "X_val = torch.tensor(X_val_scaled, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val_np, dtype=torch.long)\n",
    "X_test = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test_np, dtype=torch.long)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=64, shuffle=False)\n",
    "\n",
    "# model - use actual input dimension\n",
    "class GatingNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features=input_dim, out_features=32)\n",
    "        self.fc2 = nn.Linear(in_features=32, out_features=32)\n",
    "        self.fc3 = nn.Linear(in_features=32, out_features=16)\n",
    "        self.fc4 = nn.Linear(in_features=16, out_features=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return self.fc4(x)\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "model = GatingNet(input_dim=input_dim)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# training loop\n",
    "n_epochs = 50\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * labels.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    avg_train_loss = train_loss / total\n",
    "    train_acc = correct / total\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * labels.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    avg_val_loss = val_loss / total if total > 0 else 0.0\n",
    "    val_acc = correct / total if total > 0 else 0.0\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs} train_loss={avg_train_loss:.4f} train_acc={train_acc:.4f} val_loss={avg_val_loss:.4f} val_acc={val_acc:.4f}\")\n",
    "\n",
    "# save model\n",
    "torch.save(model.state_dict(), os.path.join(script_dir, \"gating_model_fixed.pth\"))"
   ],
   "id": "cc73f09474bb1522",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 train_loss=0.5870 train_acc=0.8718 val_loss=0.4660 val_acc=0.9075\n",
      "Epoch 2/50 train_loss=0.3714 train_acc=0.9465 val_loss=0.2745 val_acc=0.9144\n",
      "Epoch 3/50 train_loss=0.1946 train_acc=0.9421 val_loss=0.1669 val_acc=0.9144\n",
      "Epoch 4/50 train_loss=0.1218 train_acc=0.9458 val_loss=0.1516 val_acc=0.9212\n",
      "Epoch 5/50 train_loss=0.1100 train_acc=0.9421 val_loss=0.1551 val_acc=0.9247\n",
      "Epoch 6/50 train_loss=0.1053 train_acc=0.9465 val_loss=0.1531 val_acc=0.9212\n",
      "Epoch 7/50 train_loss=0.1067 train_acc=0.9407 val_loss=0.1497 val_acc=0.9178\n",
      "Epoch 8/50 train_loss=0.1056 train_acc=0.9451 val_loss=0.1496 val_acc=0.9247\n",
      "Epoch 9/50 train_loss=0.1045 train_acc=0.9473 val_loss=0.1518 val_acc=0.9212\n",
      "Epoch 10/50 train_loss=0.1020 train_acc=0.9480 val_loss=0.1518 val_acc=0.9247\n",
      "Epoch 11/50 train_loss=0.1036 train_acc=0.9458 val_loss=0.1495 val_acc=0.9212\n",
      "Epoch 12/50 train_loss=0.1027 train_acc=0.9495 val_loss=0.1531 val_acc=0.9247\n",
      "Epoch 13/50 train_loss=0.1024 train_acc=0.9502 val_loss=0.1480 val_acc=0.9178\n",
      "Epoch 14/50 train_loss=0.1020 train_acc=0.9487 val_loss=0.1516 val_acc=0.9281\n",
      "Epoch 15/50 train_loss=0.1012 train_acc=0.9473 val_loss=0.1471 val_acc=0.9178\n",
      "Epoch 16/50 train_loss=0.1014 train_acc=0.9509 val_loss=0.1473 val_acc=0.9212\n",
      "Epoch 17/50 train_loss=0.1013 train_acc=0.9531 val_loss=0.1450 val_acc=0.9247\n",
      "Epoch 18/50 train_loss=0.1007 train_acc=0.9502 val_loss=0.1444 val_acc=0.9247\n",
      "Epoch 19/50 train_loss=0.1000 train_acc=0.9480 val_loss=0.1443 val_acc=0.9247\n",
      "Epoch 20/50 train_loss=0.1008 train_acc=0.9516 val_loss=0.1506 val_acc=0.9281\n",
      "Epoch 21/50 train_loss=0.0989 train_acc=0.9516 val_loss=0.1444 val_acc=0.9247\n",
      "Epoch 22/50 train_loss=0.0999 train_acc=0.9465 val_loss=0.1436 val_acc=0.9212\n",
      "Epoch 23/50 train_loss=0.0978 train_acc=0.9531 val_loss=0.1506 val_acc=0.9178\n",
      "Epoch 24/50 train_loss=0.1020 train_acc=0.9473 val_loss=0.1427 val_acc=0.9247\n",
      "Epoch 25/50 train_loss=0.0969 train_acc=0.9502 val_loss=0.1436 val_acc=0.9212\n",
      "Epoch 26/50 train_loss=0.0997 train_acc=0.9487 val_loss=0.1432 val_acc=0.9349\n",
      "Epoch 27/50 train_loss=0.0982 train_acc=0.9480 val_loss=0.1416 val_acc=0.9315\n",
      "Epoch 28/50 train_loss=0.0984 train_acc=0.9480 val_loss=0.1433 val_acc=0.9212\n",
      "Epoch 29/50 train_loss=0.0977 train_acc=0.9516 val_loss=0.1463 val_acc=0.9281\n",
      "Epoch 30/50 train_loss=0.0979 train_acc=0.9495 val_loss=0.1400 val_acc=0.9349\n",
      "Epoch 31/50 train_loss=0.0965 train_acc=0.9495 val_loss=0.1390 val_acc=0.9247\n",
      "Epoch 32/50 train_loss=0.0973 train_acc=0.9538 val_loss=0.1399 val_acc=0.9247\n",
      "Epoch 33/50 train_loss=0.0977 train_acc=0.9487 val_loss=0.1406 val_acc=0.9281\n",
      "Epoch 34/50 train_loss=0.0961 train_acc=0.9480 val_loss=0.1382 val_acc=0.9247\n",
      "Epoch 35/50 train_loss=0.0983 train_acc=0.9516 val_loss=0.1362 val_acc=0.9212\n",
      "Epoch 36/50 train_loss=0.1002 train_acc=0.9502 val_loss=0.1390 val_acc=0.9281\n",
      "Epoch 37/50 train_loss=0.0952 train_acc=0.9509 val_loss=0.1391 val_acc=0.9281\n",
      "Epoch 38/50 train_loss=0.1007 train_acc=0.9531 val_loss=0.1404 val_acc=0.9281\n",
      "Epoch 39/50 train_loss=0.0947 train_acc=0.9531 val_loss=0.1355 val_acc=0.9212\n",
      "Epoch 40/50 train_loss=0.0954 train_acc=0.9502 val_loss=0.1356 val_acc=0.9384\n",
      "Epoch 41/50 train_loss=0.0956 train_acc=0.9531 val_loss=0.1346 val_acc=0.9247\n",
      "Epoch 42/50 train_loss=0.0954 train_acc=0.9560 val_loss=0.1335 val_acc=0.9212\n",
      "Epoch 43/50 train_loss=0.0936 train_acc=0.9495 val_loss=0.1362 val_acc=0.9315\n",
      "Epoch 44/50 train_loss=0.0951 train_acc=0.9516 val_loss=0.1371 val_acc=0.9315\n",
      "Epoch 45/50 train_loss=0.0925 train_acc=0.9531 val_loss=0.1330 val_acc=0.9247\n",
      "Epoch 46/50 train_loss=0.0953 train_acc=0.9502 val_loss=0.1326 val_acc=0.9247\n",
      "Epoch 47/50 train_loss=0.0936 train_acc=0.9509 val_loss=0.1410 val_acc=0.9247\n",
      "Epoch 48/50 train_loss=0.0917 train_acc=0.9516 val_loss=0.1315 val_acc=0.9315\n",
      "Epoch 49/50 train_loss=0.0919 train_acc=0.9509 val_loss=0.1314 val_acc=0.9247\n",
      "Epoch 50/50 train_loss=0.0921 train_acc=0.9502 val_loss=0.1307 val_acc=0.9247\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2f9eef9868ad655"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
